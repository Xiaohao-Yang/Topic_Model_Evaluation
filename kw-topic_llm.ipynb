{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea63cde3-0313-490b-96d5-551525e99273",
   "metadata": {},
   "source": [
    "## Generate topic-aware keywords for test documents from LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f92c6-d04d-451c-a00c-7823c89a6d71",
   "metadata": {},
   "source": [
    "### Step1: Generate global topics\n",
    "\n",
    "To generate global topics for the document collection from an LLM, we follow the topic generation approach in [TopicGPT](https://github.com/chtmp223/topicGPT). We have saved the output topics under the dataset folder (e.g., datasets/20News/topics.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ce8be-2ca2-4a4c-968a-d68052dcaa5e",
   "metadata": {},
   "source": [
    "### Step2: Topic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f3c850-48fc-4d63-aedb-d3179e681469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/xiaohao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/xiaohao/anaconda3/envs/walm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLM Inference ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from walm import extract_text_between_strings, generate_topic_select, generate_topics_aware\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "\n",
    "# load documents\n",
    "dataset = '20News'\n",
    "data_dict = sio.loadmat('datasets/%s/data.mat' % dataset)\n",
    "test_doc = data_dict['test_text'].tolist()\n",
    "test_doc = [doc[0][0].strip() for doc in test_doc]\n",
    "\n",
    "# take 10 documents as an example\n",
    "test_doc = test_doc[0:10]\n",
    "\n",
    "# load llm model\n",
    "model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "# model_name = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "# model_name = 'microsoft/Phi-3-mini-128k-instruct'\n",
    "# model_name = '01-ai/Yi-1.5-9B-Chat'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=torch.float16\n",
    "                                             ).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# load global topics from this dataset\n",
    "with open('datasets/%s/topics.txt' % dataset, 'r') as file:\n",
    "    topics = file.readlines()\n",
    "topics = topics[0:-1]\n",
    "topics = [extract_text_between_strings(item, \"[1]\", \"(Count:\")[0].strip() for item in topics]\n",
    "\n",
    "# run topic selection\n",
    "save_path = 'step1_topic-select.txt'\n",
    "doc_topics = generate_topic_select(model, tokenizer, topics, test_doc, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6698b9-ba9d-43b5-83af-faeb5ea937a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Topics': ['Technology and Electronics', 'Software Development', 'Economic and Employment Issues']}\n",
      "{'Topics': ['Consumer Rights', 'Law and Justice', 'Ethics', 'Society']}\n",
      "{'Topics': ['Sports Statistics', 'History']}\n",
      "{'Topics': ['Sports Statistics']}\n",
      "{'Topics': ['Technology and Electronics', 'Software Development', 'Internet Culture', 'Communication']}\n",
      "{'Topics': ['Technology and Electronics', 'Software Development']}\n",
      "{'Topics': ['Transportation', 'Consumer Rights', 'Society']}\n",
      "{'Topics': ['Technology and Electronics', 'Repair and Maintenance', 'Software Development']}\n",
      "{'Topics': ['Technology and Electronics', 'Consumer Rights']}\n",
      "{'Topics': ['Society', 'Ethics', 'Religion']}\n"
     ]
    }
   ],
   "source": [
    "for item in doc_topics:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750d2d9-ca72-4182-9166-5db9624d1a52",
   "metadata": {},
   "source": [
    "### Step2: Topic-Aware keywords generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a8a7a7-ba62-4939-9fd6-2d087ce717c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:38,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Error when parsing answer:\n",
      "I apologize, but it seems like there's been a mistake. You didn't provide a document about 'Consumer Rights'. Instead, you mentioned a case about abortion rights.\n",
      "\n",
      "If you'd like to provide the document about 'Consumer Rights', I'd be happy to help you with indexing words.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# load selected topics from test documents\n",
    "with open('step1_topic-select.txt', 'r') as file:\n",
    "    doc_topics = file.readlines()\n",
    "\n",
    "# define save path and run generation\n",
    "save_path = 'step2_topic-aware_kws.txt'\n",
    "outputs = generate_topics_aware(model, tokenizer, doc_topics, test_doc, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8144e22-183b-4441-a40a-988df1db6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology, Development, Sale, Software, Economic, Graphics, Harvard, Employment, Electronics, Issues, Price, Windows, Harvard Graphics\n",
      "Ethical, Justice, Constitution, Societal, Morality, Abortion, Bioethics, Moral, Rights, Ethics, Law\n",
      "History, Strike, Sports, Baseball, Mound, Zone, Statistics\n",
      "Role, Plus/minus, Players, Context, Statistics\n",
      "Async Solutions, Graphics Accelerator, Efficiency, Internet Culture, X11 Clients, Communication, Software Development, X11, Clients\n",
      "Technology, UART, Serial Communication, Software Development, Electronics, Hardware Interrupts, Interrupts, Hardware, Windows\n",
      "Train, Station, City, Protection, Dispute, Airport, Cities, Infrastructure, Complaint, Consumer, Rights, Society, Transportation\n",
      "PCTools, Data Error, Error, IDE drive, IDE, Drive, Low Level Format, Maintenance, Data error, Disk recovery, IDE Drive, Repair, Low level format, Sector Marking, Disk Recovery\n",
      "Technology, Sound, Sale, Protection, Purchase, Electronics, Super 8mm, Projector, Consumer, Rights\n",
      "Life, Morality, Violence, Killing, Moral, Values, Society, Value\n"
     ]
    }
   ],
   "source": [
    "for item in outputs:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
